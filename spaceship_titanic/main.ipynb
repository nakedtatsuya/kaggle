{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "import matplotlib as mpl\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9766, 0.4976, 0.0354],\n",
      "        [0.9673, 0.3815, 0.6364],\n",
      "        [0.1998, 0.0442, 0.5488],\n",
      "        [0.3582, 0.3579, 0.9223],\n",
      "        [0.0742, 0.0795, 0.0307]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   8693 non-null   object \n",
      " 1   HomePlanet    8492 non-null   object \n",
      " 2   CryoSleep     8476 non-null   object \n",
      " 3   Cabin         8494 non-null   object \n",
      " 4   Destination   8511 non-null   object \n",
      " 5   Age           8514 non-null   float64\n",
      " 6   VIP           8490 non-null   object \n",
      " 7   RoomService   8512 non-null   float64\n",
      " 8   FoodCourt     8510 non-null   float64\n",
      " 9   ShoppingMall  8485 non-null   float64\n",
      " 10  Spa           8510 non-null   float64\n",
      " 11  VRDeck        8505 non-null   float64\n",
      " 12  Name          8493 non-null   object \n",
      " 13  Transported   8693 non-null   bool   \n",
      "dtypes: bool(1), float64(6), object(7)\n",
      "memory usage: 891.5+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os.path\n",
    "\n",
    "\n",
    "train_all = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "\n",
    "NUMERIC_FEATURE_NAMES = [\n",
    "    \"Age\",\n",
    "    \"RoomService\",\n",
    "    \"FoodCourt\",\n",
    "    \"ShoppingMall\",\n",
    "    \"Spa\",\n",
    "    \"VRDeck\",\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURE_NAMES1 = [\"HomePlanet\",\"CryoSleep\",\"Destination\",\"VIP\"]\n",
    "\n",
    "\n",
    "train_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_file = \"test_data.csv\"\n",
    "test.to_csv(test_data_file, index=False, header=True)\n",
    "\n",
    "train_all.drop(['PassengerId', 'Cabin','Name','CryoSleep','VIP', 'HomePlanet', 'Destination'],axis =1 , inplace=True)\n",
    "test.drop(['PassengerId', 'Cabin','Name','CryoSleep','VIP', 'HomePlanet', 'Destination'],axis = 1 ,inplace=True)\n",
    "train_all.Transported.replace([True,False], [\"1\", \"0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_all[\"Age\"].fillna(train_all[\"Age\"].mean(skipna=True), inplace=True)\n",
    "test[\"Age\"].fillna(test[\"Age\"].mean(skipna=True), inplace=True)\n",
    "\n",
    "train_all[\"RoomService\"].fillna(train_all[\"RoomService\"].mean(skipna=True), inplace=True)\n",
    "test[\"RoomService\"].fillna(test[\"RoomService\"].mean(skipna=True), inplace=True)\n",
    "\n",
    "train_all[\"FoodCourt\"].fillna(train_all[\"FoodCourt\"].mean(skipna=True), inplace=True)\n",
    "test[\"FoodCourt\"].fillna(test[\"FoodCourt\"].mean(skipna=True), inplace=True)\n",
    "\n",
    "train_all[\"ShoppingMall\"].fillna(train_all[\"ShoppingMall\"].mean(skipna=True), inplace=True)\n",
    "test[\"ShoppingMall\"].fillna(test[\"ShoppingMall\"].mean(skipna=True), inplace=True)\n",
    "\n",
    "train_all[\"Spa\"].fillna(train_all[\"Spa\"].mean(skipna=True), inplace=True)\n",
    "test[\"Spa\"].fillna(test[\"Spa\"].mean(skipna=True), inplace=True)\n",
    "\n",
    "train_all[\"VRDeck\"].fillna(train_all[\"VRDeck\"].mean(skipna=True), inplace=True)\n",
    "test[\"VRDeck\"].fillna(test[\"VRDeck\"].mean(skipna=True), inplace=True)\n",
    "\n",
    "\n",
    "# train_all[\"HomePlanet\"].fillna('Kepler', inplace=True)\n",
    "# test[\"HomePlanet\"].fillna('Kepler', inplace=True)\n",
    "\n",
    "# train_all[\"Destination\"].fillna('TRAPPIST-1e', inplace=True)\n",
    "# test[\"Destination\"].fillna('TRAPPIST-1e', inplace=True)\n",
    "\n",
    "train_all.dropna(inplace = True)\n",
    "test.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_HEADER = [\n",
    "    # \"HomePlanet\",\n",
    "    # \"Destination\",\n",
    "    \"Age\",\n",
    "    \"RoomService\",\n",
    "    \"FoodCourt\",\n",
    "    \"ShoppingMall\",\n",
    "    \"Spa\",\n",
    "    \"VRDeck\",\n",
    "    \"Transported\",\n",
    "    ]\n",
    "\n",
    "train_data_file = \"train_data.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = tf.data.experimental.make_csv_dataset(\n",
    "#     \"./train_data.csv\",\n",
    "#     batch_size=20,\n",
    "#     column_names=CSV_HEADER,\n",
    "#     label_name=\"Transported\",\n",
    "#     num_epochs=1,\n",
    "#     shuffle=True\n",
    "# )\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_from_csv(csv_file_path, shuffle=False, batch_size=128):\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        csv_file_path,\n",
    "        batch_size=batch_size,\n",
    "        column_names=CSV_HEADER,\n",
    "        label_name=\"Transported\",\n",
    "        num_epochs=1,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    return dataset.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6953 entries, 0 to 6952\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   28.0    6953 non-null   float64\n",
      " 1   0.0     6953 non-null   float64\n",
      " 2   55.0    6953 non-null   float64\n",
      " 3   0.0.1   6953 non-null   float64\n",
      " 4   656.0   6953 non-null   float64\n",
      " 5   0.0.2   6953 non-null   float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 326.0 KB\n"
     ]
    }
   ],
   "source": [
    "# train_all = pd.read_csv('./train_data.csv')\n",
    "# test = pd.read_csv('./test_data.csv')\n",
    "\n",
    "train, valid = train_test_split(train_all, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "train_X, train_y = train.drop('Transported', axis=1), train['Transported']\n",
    "valid_X, valid_y = valid.drop('Transported', axis=1), valid['Transported']\n",
    "\n",
    "train_X.to_csv(\"./train_x.csv\", index=False, header=False)\n",
    "train_y.to_csv(\"./train_y.csv\", index=False, header=False)\n",
    "train_X.to_csv(\"./valid_x.csv\", index=False, header=False)\n",
    "train_y.to_csv(\"./valid_y.csv\", index=False, header=False)\n",
    "\n",
    "train_X, train_y = pd.read_csv('./train_x.csv'), pd.read_csv('./train_y.csv')\n",
    "valid_X, valid_y = pd.read_csv('./valid_x.csv'), pd.read_csv('./valid_y.csv')\n",
    "\n",
    "\n",
    "\n",
    "train_X.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# train, valid = train_test_split(train_all, test_size=0.2, random_state=42, shuffle=True)\n",
    "# train.to_csv(\"./train_data.csv\", index=False, header=True)\n",
    "# valid.to_csv(\"./valid_data.csv\", index=False, header=True)\n",
    "\n",
    "# train_dataset = get_dataset_from_csv(\"./train_data.csv\")\n",
    "# valid_dataset = get_dataset_from_csv(\"./valid_data.csv\")\n",
    "\n",
    "\n",
    "# train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_X[\"relation\"] = train_X[\"PassengerId\"].str.split(\"_\").str[1].astype(int)\n",
    "# train_X[\"relation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_encoder = OneHotEncoder()\n",
    "# housing_cat_encoded  = cat_encoder.fit_transform(train_X[[\"HomePlanet\"]])\n",
    "# housing_cat_encoded.toarray()\n",
    "# train_X[\"HomePlanet\"] = housing_cat_encoded.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_encoder = OneHotEncoder()\n",
    "# housing_cat_encoded  = cat_encoder.fit_transform(train_X[[\"Destination\"]])\n",
    "# housing_cat_encoded.toarray()\n",
    "# train_X[\"Destination\"] = housing_cat_encoded.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X[\"Deck\"] = train_X[\"Cabin\"].str[0]\n",
    "\n",
    "# train_X[\"Side\"] = train_X[\"Cabin\"].str[2]\n",
    "\n",
    "# train_X.drop([\"Cabin\", \"Name\"], axis=1, inplace=True)\n",
    "\n",
    "# cat_encoder = OneHotEncoder()\n",
    "# housing_cat_encoded  = cat_encoder.fit_transform(train_X[[\"Deck\"]])\n",
    "# housing_cat_encoded.toarray()\n",
    "# train_X[\"Deck\"] = housing_cat_encoded.toarray()\n",
    "\n",
    "# cat_encoder = OneHotEncoder()\n",
    "# housing_cat_encoded  = cat_encoder.fit_transform(train_X[[\"Side\"]])\n",
    "# housing_cat_encoded.toarray()\n",
    "# train_X[\"Side\"] = housing_cat_encoded.toarray()\n",
    "\n",
    "# train_X[\"Deck\"]\n",
    "# train_X[\"Side\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X = np.asarray(train_X).astype('float32')\n",
    "# train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "model = keras.Sequential([\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.5164 - accuracy: 0.7690 - val_loss: 0.5444 - val_accuracy: 0.7571\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.5108 - accuracy: 0.7713 - val_loss: 0.5429 - val_accuracy: 0.7568\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.5105 - accuracy: 0.7733 - val_loss: 0.5422 - val_accuracy: 0.7565\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.5122 - accuracy: 0.7725 - val_loss: 0.5391 - val_accuracy: 0.7592\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 2s 8ms/step - loss: 0.5074 - accuracy: 0.7728 - val_loss: 0.5454 - val_accuracy: 0.7556\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 2s 8ms/step - loss: 0.5050 - accuracy: 0.7696 - val_loss: 0.5408 - val_accuracy: 0.7594\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 2s 9ms/step - loss: 0.5070 - accuracy: 0.7742 - val_loss: 0.5411 - val_accuracy: 0.7590\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 2s 11ms/step - loss: 0.5088 - accuracy: 0.7741 - val_loss: 0.5403 - val_accuracy: 0.7595\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.5051 - accuracy: 0.7768 - val_loss: 0.5427 - val_accuracy: 0.7456\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 2s 7ms/step - loss: 0.5086 - accuracy: 0.7707 - val_loss: 0.5344 - val_accuracy: 0.7638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f49fa8cf210>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_y, epochs=10, validation_data=(valid_X, valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55829257],\n",
       "       [0.1011159 ],\n",
       "       [0.5885259 ],\n",
       "       ...,\n",
       "       [0.56771463],\n",
       "       [0.4226867 ],\n",
       "       [0.6471786 ]], dtype=float32)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "prediction = pd.DataFrame(y_pred, columns=['Transported'])\n",
    "\n",
    "prediction[\"PassengerId\"] = pd.read_csv('./test_data.csv')[\"PassengerId\"]\n",
    "\n",
    "prediction[\"Transported\"].loc[prediction['Transported'] > 0.5] = True\n",
    "prediction[\"Transported\"].loc[prediction['Transported'] <= 0.5] = False\n",
    "\n",
    "prediction.to_csv(\"./submit.csv\", index=False, header=True)\n",
    "\n",
    "\n",
    "# .to_csv('submit.csv')\n",
    "# prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
